# üöÄ Runbook: Personal Observability Pipeline (Audit-X)
*Actualizado: 29 de enero, 2026*

## üîÄ Flujo Git y CI
El trabajo se hace en ramas; la integraci√≥n a `main` es solo v√≠a Pull Request, con el CI en verde (lint y tests de Rails y Python). El workflow est√° en la ra√≠z del repo: `.github/workflows/ci.yml`. Coolify despliega desde `main`.

---

## üõ† 1. Gesti√≥n de Infraestructura (Docker)
El stack completo corre en contenedores. No es necesario instalar Ruby o Kafka localmente.

*   **Levantar el stack (Recomendado):**
    ```bash
    docker compose up -d
    ```
*   **Verificar salud de los servicios (Healthchecks):**
    ```bash
    docker compose ps
    ```
    *Nota: `redpanda` y `db` deben aparecer como `(healthy)` antes de que `web` inicie.*
*   **Logs espec√≠ficos para depurar:**
    ```bash
    docker compose logs -f web            # Logs de la interfaz Rails
    docker compose logs -f karafka_worker # Logs del consumidor de Kafka
    ```
*   **Apagar y limpiar vol√∫menes (Reset de DBs):**
    ```bash
    docker compose down -v
    ```

### üåê Dashboard de Control
- **Audit-X (Rails):** [http://localhost:3000](http://localhost:3000) (Gesti√≥n y Aprobaci√≥n)
- **Kafka UI:** [http://localhost:8080](http://localhost:8080) (Monitoreo de t√≥picos)
- **Eventos Kafka (AsyncAPI):** [asyncapi.yaml](asyncapi.yaml) ‚Äî Especificaci√≥n de t√≥picos y payloads (transacciones_raw, transacciones_clean, file_uploaded, file_results, domain_events).
- **Grafana:** [http://localhost:3001](http://localhost:3001) (Visualizaci√≥n final)
- **InfluxDB:** [http://localhost:8086](http://localhost:8086) (M√©tricas Raw)

---

## üíé 2. Configuraci√≥n Inicial (Instalaci√≥n)
Si agregaste gemas nuevas o est√°s en una instalaci√≥n limpia:

1. **Sincronizar Gemas:**
   ```bash
   docker compose run --rm web bundle install
   ```
2. **Preparar Base de Datos:**
   ```bash
   docker compose exec web rails db:prepare
   ```


---

## üì• 3. Fase 1: Ingesta (Python)
Env√≠a los datos de los extractores (Visa/Amex) hacia Kafka.

```bash
# Activar entorno virtual
source .venv/bin/activate
# Ejecutar ingesta
python main.py
```
*Los eventos quedar√°n en el t√≥pico `transacciones_raw` y entrar√°n autom√°ticamente a la web de Rails en estado "Pendiente".*

2. **Listar archivos en s3:**
```bash
docker exec -it minio_s3 mc alias set local http://localhost:9000 {user} {password}
```

```bash
docker exec -it minio_s3 mc du local/bank-ingestion
```
---

## üîç 4. Fase 2: Curadur√≠a y Enriquecimiento (Rails)
En esta fase, los datos est√°n en PostgreSQL pero **no han llegado a InfluxDB**.

1. Entra a [http://localhost:3000/transactions](http://localhost:3000/transactions).
2. Revisa las categor√≠as sugeridas por el `CategorizerService`.
3. Ajusta la categor√≠a o el sentimiento si es necesario.
4. Presiona **"Aprobar"**. 
   *Esto publica el evento en `transacciones_clean`.*

---

## üìä 5. Fase 3: Visualizaci√≥n (Telegraf + Influx + Grafana)
El servicio **Telegraf** est√° configurado para mover autom√°ticamente todo lo que aparece en el t√≥pico `transacciones_clean` hacia InfluxDB.

1. Abre **Grafana** [http://localhost:3001](http://localhost:3001).
2. Usa el Data Source de InfluxDB (Bucket: `finanzas`).
3. Filtra por los tags: `categoria`, `sentimiento` o `red`.

---

## ‚öôÔ∏è Motor de Reglas y Extractores

### Reglas de categor√≠a (export/import)
En [http://localhost:3000/category_rules](http://localhost:3000/category_rules) puedes:
- **Exportar:** descargar todas las reglas en JSON (jer√°rquico: ra√≠z ‚Üí hijos).
- **Importar:** subir un archivo JSON o pegar el contenido; el servicio crea/actualiza reglas por `name` + `pattern` + `parent_name` (idempotente).

Servicio: `CategoryRulesExportImportService` (export/import). Rutas: `GET /category_rules/export`, `POST /category_rules/import`.

### Extractores de ingesta (Python)
Adem√°s de los extractores por banco (Visa, Amex, BBVA CSV), existe el extractor **BBVA PDF Visa** (`bbva_pdf_visa`) para res√∫menes de tarjeta en PDF. Usa `pdfplumber`; est√° registrado en `ingestion-engine/bank_extractors/` y en `web-enrichment-app/config/initializers/bank_schemas.rb`. Tests: `ingestion-engine/tests/test_extractors_pdf.py`.

---

## üíæ Backup y restauraci√≥n de bases de datos

### Backup a demanda (desarrollo y test)
- **Base de desarrollo:** `make backup-db` ‚Äî guarda un volcado en `backups/backup_dev_YYYYMMDD_HHMMSS.sql`. La carpeta `backups/` est√° en `.gitignore`.
- **Base de test:** `make backup-db-test` ‚Äî guarda en `backups/backup_test_YYYYMMDD_HHMMSS.sql`.

### Restaurar (revertir cambios)
- **Desarrollo:** `make restore-db FILE=backups/backup_dev_YYYYMMDD_HHMMSS.sql` ‚Äî **sobrescribe** la base de desarrollo con el dump indicado. Cierra conexiones activas (p. ej. reinicia `web`) si falla por conexiones.
- **Test:** `make restore-db-test FILE=backups/backup_test_YYYYMMDD_HHMMSS.sql` ‚Äî igual para la base de test.

### Backup autom√°tico en producci√≥n
En producci√≥n debe existir un **backup autom√°tico** (cron o job en Coolify/servidor) que ejecute `pg_dump` contra la base de producci√≥n (`audit_x_prod`) y guarde los archivos con retenci√≥n (ej. 7 d√≠as diarios). No forma parte del repo de la aplicaci√≥n; es tarea de infraestructura. Ver ejemplos en [DOCS/INFRA_MEMORANDUM.md](DOCS/INFRA_MEMORANDUM.md) (script `backup.sh`) y [DOCS/DEVOPS-ROADMAP.md](DOCS/DEVOPS-ROADMAP.md) (secci√≥n Backup Automatizado). Para restaurar en producci√≥n: mismo concepto que `restore-db` pero contra la DB de producci√≥n y con precauci√≥n extra (ventana de mantenimiento, notificaci√≥n).

### Rollback en Postgres
**No existe "rollback" de datos ya confirmados.** Una vez hecho `COMMIT`, no hay comando para deshacer esa transacci√≥n. La recuperaci√≥n se hace **restaurando desde un backup** (pg_dump/pg_restore o PITR si est√° configurado). Por eso el backup a demanda y autom√°tico es la pieza clave para poder revertir.

---

## üîÑ Recuperaci√≥n y regeneraci√≥n de transacciones (desde eventos)

Permite repoblar la tabla `transactions` desde los t√≥picos Kafka sin restaurar un backup de Postgres. Dos modos:

### Recuperaci√≥n desde transacciones_clean (recovery desde eventos)

Rails **no** consume el t√≥pico `transacciones_clean` en tiempo normal (solo Telegraf lo lee para InfluxDB). Para recuperar la base de datos desde los eventos ya aprobados:

- **Cu√°ndo:** Tras p√©rdida de la tabla `transactions` o para repoblar desde la ‚Äúfuente de verdad‚Äù que son los eventos clean.
- **Comando:** `make recover-transactions-from-clean`
- **Qu√© hace:** Un consumidor one-off (rdkafka) lee desde el inicio del t√≥pico `transacciones_clean` y hace **upsert** por `event_id` en `transactions` (crea o actualiza, siempre con `aprobado: true`). Idempotente.
- **Limitaci√≥n:** Los mensajes clean no incluyen `numero_tarjeta`; esos campos quedar√°n vac√≠os tras la recuperaci√≥n. Opcionalmente se puede ejecutar despu√©s `make backfill-card-numbers` si los datos siguen en `transacciones_raw`.

Servicio: `RecoveryFromCleanService`. Rake: `rails data:recover_from_clean`. Tests: `bin/rails test test/services/recovery_from_clean_service_test.rb`.

### Regeneraci√≥n desde transacciones_raw (rewind del circuito normal)

Relee el t√≥pico `transacciones_raw` con el consumidor Karafka existente (`TransactionsConsumer`) para volver a crear las transacciones desde cero.

- **Cu√°ndo:** Para ‚Äúrebobinar‚Äù el flujo: borrar transacciones y repoblar desde raw (p. ej. tras cambiar reglas de categorizaci√≥n o corregir un bug en el consumer).
- **Comando:** `make regenerate-transactions-from-raw`
- **Qu√© hace:** 1) Borra solo la tabla `transactions` (`data:clean_transactions`). 2) Rebobina el consumer group `enrichment_manager_v3` al inicio del t√≥pico (y de `file_results`). 3) Reinicia el worker Karafka. El worker vuelve a consumir todos los mensajes de `transacciones_raw` y crea de nuevo los registros en `transactions` (pendientes de aprobaci√≥n).
- **Nota:** No hace falta modificar `TransactionsConsumer`; al borrar antes las transacciones, no hay registros aprobados que se salten.

Targets auxiliares:
- `make clean-transactions-only` ‚Äî Borra solo `transactions` (no `SourceFile`).
- `make rebind-karafka-consumer` ‚Äî Rebobina el consumer group al inicio (√∫til tambi√©n para backfill de `numero_tarjeta` si se combina con l√≥gica que permita actualizar aprobadas).

---

## üìù Notas T√©cnicas y Mantenimiento

1. **Idempotencia:** El `event_id` (hash SHA-256) previene duplicados. Si un gasto ya fue aprobado, el pipeline de Rails lo ignorar√° si intentas re-ingestarlo.
2. **Karafka Boot:** Si el worker no arranca, verifica que `app/consumers/application_consumer.rb` exista y que `karafka.rb` use `"TransactionsConsumer"` como string.
3. **Persistencia:** Los datos residen en vol√∫menes nombrados de Docker (`postgres_data`, `influxdb_data`). No borrar a menos que se desee un hard-reset.
4. **Sincronizaci√≥n:** Recuerda: **Escribe c√≥digo en local, ejecuta en Docker.** Cualquier archivo generado con `rails generate` aparecer√° en tu carpeta local gracias a los vol√∫menes montados.

### Hotfix: `solid_cache_entries` / Solid Queue no existen (401 en login)
Si en producci√≥n aparece **`PG::UndefinedTable: relation "solid_cache_entries" does not exist`** al hacer login (porque Rack::Attack usa Solid Cache para throttling):

- **Opci√≥n A (recomendada):** Desplegar este hotfix y ejecutar migraciones en producci√≥n:
  ```bash
  RAILS_ENV=production bundle exec rails db:migrate
  ```
  Las migraciones `20260130120000_create_solid_cache_entries` y `20260130120001_create_solid_queue_tables` crean las tablas en la base principal.

- **Opci√≥n B (sin redesplegar):** En el servidor de producci√≥n, con la app ya desplegada:
  ```bash
  cd /ruta/a/web-enrichment-app
  RAILS_ENV=production bundle exec rails db:schema:load:cache
  RAILS_ENV=production bundle exec rails db:schema:load:queue
  ```
  Eso carga los esquemas de cache y queue en la misma base (si usas una sola `DATABASE_URL`).

---
*Tip: Usa `Ctrl + Shift + V` en VS Code para previsualizar este documento.*
