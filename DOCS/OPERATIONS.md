# üöÄ Runbook: Personal Observability Pipeline (Audit-X)
*Actualizado: 29 de enero, 2026*

## üîÄ Flujo Git y CI
El trabajo se hace en ramas; la integraci√≥n a `main` es solo v√≠a Pull Request, con el CI en verde (lint y tests de Rails y Python). El workflow est√° en la ra√≠z del repo: `.github/workflows/ci.yml`. Coolify despliega desde `main`.

---

## üõ† 1. Gesti√≥n de Infraestructura (Docker)
El stack completo corre en contenedores. No es necesario instalar Ruby o Kafka localmente.

*   **Levantar el stack (Recomendado):**
    ```bash
    docker compose up -d
    ```
*   **Verificar salud de los servicios (Healthchecks):**
    ```bash
    docker compose ps
    ```
    *Nota: `redpanda` y `db` deben aparecer como `(healthy)` antes de que `web` inicie.*
*   **Logs espec√≠ficos para depurar:**
    ```bash
    docker compose logs -f web            # Logs de la interfaz Rails
    docker compose logs -f karafka_worker # Logs del consumidor de Kafka
    ```
*   **Apagar y limpiar vol√∫menes (Reset de DBs):**
    ```bash
    docker compose down -v
    ```

### üåê Dashboard de Control
- **Audit-X (Rails):** [http://localhost:3000](http://localhost:3000) (Gesti√≥n y Aprobaci√≥n)
- **Kafka UI:** [http://localhost:8080](http://localhost:8080) (Monitoreo de t√≥picos)
- **Eventos Kafka (AsyncAPI):** [asyncapi.yaml](asyncapi.yaml) ‚Äî Especificaci√≥n de t√≥picos y payloads (transacciones_raw, transacciones_clean, file_uploaded, file_results, domain_events).
- **Grafana:** [http://localhost:3001](http://localhost:3001) (Visualizaci√≥n final)
- **InfluxDB:** [http://localhost:8086](http://localhost:8086) (M√©tricas Raw)

---

## üíé 2. Configuraci√≥n Inicial (Instalaci√≥n)
Si agregaste gemas nuevas o est√°s en una instalaci√≥n limpia:

1. **Sincronizar Gemas:**
   ```bash
   docker compose run --rm web bundle install
   ```
2. **Preparar Base de Datos:**
   ```bash
   docker compose exec web rails db:prepare
   ```
   *En producci√≥n, `rails db:migrate` crea tambi√©n las tablas de Solid Cache y Solid Queue (Rack::Attack y Active Job).*

---

## üì• 3. Carga de archivos e ingesta

### Flujo completo

1. **Usuario sube archivo** en [http://localhost:3000/source_files](http://localhost:3000/source_files): selecciona banco, adjunta Excel/CSV/PDF (o conecta Google Sheets para AMEX).
2. **Rails (ExcelUploaderService)** guarda el archivo en MinIO y publica en el t√≥pico `file_uploaded`.
3. **Python (ingestion_worker)** consume `file_uploaded`, descarga de MinIO, ejecuta el extractor seg√∫n el banco, publica en `transacciones_raw` y en `file_results`.
4. **Rails (TransactionsConsumer)** consume `transacciones_raw` y persiste en PostgreSQL (pendientes de aprobaci√≥n).
5. **Rails (FileResultsConsumer)** consume `file_results` y actualiza el estado del SourceFile (transacciones_count, extractor, mensaje).

### Bancos y extractores

| Banco | Tipo | Par√°metros | Ubicaci√≥n |
|-------|------|------------|-----------|
| `visa` | CSV | ‚Äî | `bank_extractors/visa_extractor.py` |
| `bbva` | CSV/Excel | card_number, card_network | `bank_extractors/bbva_extractor.py` |
| `amex` | Google Sheets | credit_card, spreadsheet_id, sheet | `bank_extractors/amex_extractor.py` |
| `bbva_pdf_visa` | PDF | card_number | `bank_extractors/bbva_pdf_extractor.py` |
| `bapro_pdf_visa` | PDF | card_number | `bank_extractors/bapro_pdf_extractor.py` |
| `amex_pdf` | PDF | card_number, year | `bank_extractors/amex_pdf_extractor.py` |

Los par√°metros se definen en `web-enrichment-app/config/initializers/bank_schemas.rb`. El formulario de carga los solicita din√°micamente seg√∫n el banco.

### Listar archivos en MinIO

```bash
docker exec -it minio_s3 mc alias set local http://localhost:9000 {user} {password}
docker exec -it minio_s3 mc du local/bank-ingestion
```

---

## üîç 4. Curadur√≠a y aprobaci√≥n (Rails)

En esta fase, los datos est√°n en PostgreSQL pero **no han llegado a InfluxDB** hasta que se aprueben.

1. Entra a [http://localhost:3000/transactions](http://localhost:3000/transactions).
2. Revisa las categor√≠as sugeridas por el `CategorizerService`.
3. Ajusta la categor√≠a, subcategor√≠a o sentimiento si es necesario.
4. **Edici√≥n en l√≠nea:** Los cambios se guardan autom√°ticamente (auto-save) mientras la transacci√≥n sigue pendiente. El flag `manually_edited` evita que las reglas din√°micas sobrescriban correcciones manuales.
5. Presiona **"Aprobar"** para publicar en `transacciones_clean`.
6. **Aprobar similares:** Si varias transacciones comparten la misma categor√≠a/sentimiento sugerida, puedes aprobarlas en bloque. El modal muestra el listado previo a confirmar.

### Audit corrections (correcciones en lote)

En [http://localhost:3000/audit_corrections](http://localhost:3000/audit_corrections) puedes corregir transacciones ya aprobadas. Navegaci√≥n prev/siguiente entre registros; los cambios se republican en `transacciones_clean` para actualizar InfluxDB.

---

## üìä 5. Visualizaci√≥n (Telegraf + InfluxDB + Grafana)

El servicio **Telegraf** consume `transacciones_clean` y escribe en InfluxDB.

1. Abre **Grafana** [http://localhost:3001](http://localhost:3001).
2. Usa el Data Source de InfluxDB (Bucket: `finanzas` o el configurado en `INFLUX_BUCKET`).
3. Filtra por los tags: `categoria`, `sentimiento` o `red`.

### Estructura en InfluxDB (telegraf.conf)

- **Tags:** `event_id`, `moneda`, `red` (definen la serie).
- **Fields:** `monto`, `categoria`, `sub_categoria`, `sentimiento`, `detalles`, `numero_tarjeta`, `en_cuotas`, `descripcion_cuota`.
- **Timestamp:** `fecha` de la transacci√≥n.

---

## ‚öôÔ∏è Motor de Reglas y Extractores

### Reglas de categor√≠a (export/import)

En [http://localhost:3000/category_rules](http://localhost:3000/category_rules) puedes:
- **Exportar:** descargar todas las reglas en JSON (jer√°rquico: ra√≠z ‚Üí hijos).
- **Importar:** subir un archivo JSON o pegar el contenido. El servicio es idempotente: unicidad por `name` + nivel (`parent_id`). Si existe una regla con el mismo nombre en el mismo nivel, se actualiza en lugar de duplicar.

Servicio: `CategoryRulesExportImportService`. Rutas: `GET /category_rules/export`, `POST /category_rules/import`.

### Extractores de ingesta (Python)

Extractores disponibles: Visa CSV, BBVA CSV, AMEX (Google Sheets), BBVA PDF Visa, BAPRO PDF Visa, AMEX PDF. Usan `pdfplumber` para PDF. Registrados en `ingestion-engine/bank_extractors/` y `web-enrichment-app/config/initializers/bank_schemas.rb`. Tests: `ingestion-engine/tests/test_extractors_pdf.py`, `test_extractors.py`.

---

## üíæ Backup y restauraci√≥n

### Backup a demanda (todos los servicios)

| Target | Qu√© guarda | Salida |
|--------|------------|--------|
| `make backup-db` | PostgreSQL (desarrollo) | `backups/backup_dev_YYYYMMDD_HHMMSS.sql` |
| `make backup-db-test` | PostgreSQL (test) | `backups/backup_test_YYYYMMDD_HHMMSS.sql` |
| `make backup-influx` | InfluxDB (m√©tricas, bucket) | `backups/influx_backup_YYYYMMDD_HHMMSS/` |
| `make backup-grafana` | Grafana (dashboards, datasources, usuarios) | `backups/grafana_YYYYMMDD_HHMMSS.tar.gz` |
| `make backup-minio` | MinIO (archivos subidos: Excel, PDF) | `backups/minio_YYYYMMDD_HHMMSS.tar.gz` |
| `make backup-redpanda` | Redpanda/Kafka (logs de t√≥picos) | `backups/redpanda_YYYYMMDD_HHMMSS.tar.gz` |
| **`make backup`** | Postgres + InfluxDB + Grafana + MinIO | Varios archivos en `backups/` |

La carpeta `backups/` est√° en `.gitignore`. Para InfluxDB se requieren `INFLUX_ORG` e `INFLUX_TOKEN` en `.env`.

### ¬øHace falta backup de MinIO y Kafka?

- **MinIO (S3):** **S√≠, recomendado.** Contiene los archivos originales subidos (Excel, PDF). Si se pierden, no podr√°s re-procesar desde origen sin volver a subir. `make backup-minio` hace un volcado del volumen en un `.tar.gz`.
- **Kafka (Redpanda):** **Opcional.** Los mensajes en los t√≥picos se pueden re-alimentar desde Postgres (`recover-transactions-from-clean`) o re-subiendo archivos a MinIO y re-ingiriendo. El backup del volumen (`make backup-redpanda`) solo tiene sentido para **recuperaci√≥n ante desastres** (restaurar el volumen completo); no es necesario para el d√≠a a d√≠a. Si prefieres no hacerlo, om√≠telo y usa `make backup` (que no incluye Redpanda) o ejecuta solo los targets que necesites.

### Restaurar Postgres (revertir cambios)
- **Desarrollo:** `make restore-db FILE=backups/backup_dev_YYYYMMDD_HHMMSS.sql` ‚Äî **sobrescribe** la base de desarrollo. Cierra conexiones activas (p. ej. reinicia `web`) si falla por conexiones.
- **Test:** `make restore-db-test FILE=backups/backup_test_YYYYMMDD_HHMMSS.sql` ‚Äî igual para la base de test.

Restaurar InfluxDB/Grafana/MinIO/Redpanda desde un backup requiere procedimientos manuales (ej. `influx restore`, reemplazar contenido del volumen de Grafana/MinIO). Consulta la documentaci√≥n de cada servicio si lo necesitas.

### Backup autom√°tico en producci√≥n

En producci√≥n debe existir un **backup autom√°tico** (cron o job en Coolify/servidor). Ejemplo de script (`backup.sh`) para PostgreSQL + subida a MinIO:

```bash
#!/bin/bash
TIMESTAMP=$(date +%Y-%m-%d_%H-%M-%S)
BACKUP_NAME="backup_audit_x_$TIMESTAMP.sql.gz"
CONTAINER_DB="$(docker ps -qf 'name=postgres' | head -1)"  # O el nombre del contenedor de Postgres

echo "üì¶ Iniciando dump..."
docker exec $CONTAINER_DB pg_dump -U postgres audit_x_prod | gzip > /tmp/$BACKUP_NAME

# Opcional: subir a MinIO/S3
# mc cp /tmp/$BACKUP_NAME myminio/backups-proyecto/
# find ... -mtime +30 -delete  # Retenci√≥n

rm /tmp/$BACKUP_NAME
echo "‚úÖ Backup completado: $BACKUP_NAME"
```

Para InfluxDB/Grafana/MinIO, usar los mismos targets que en desarrollo (`make backup-influx`, etc.). Ver [DOCS/DEVOPS-ROADMAP.md](DOCS/DEVOPS-ROADMAP.md) para prioridades.

### Rollback en Postgres
**No existe "rollback" de datos ya confirmados.** Una vez hecho `COMMIT`, la recuperaci√≥n se hace **restaurando desde un backup**. Por eso el backup a demanda y autom√°tico es la pieza clave.

---

## üîÑ Recuperaci√≥n y regeneraci√≥n de transacciones (desde eventos)

Permite repoblar la tabla `transactions` desde los t√≥picos Kafka sin restaurar un backup de Postgres. Dos modos:

### Recuperaci√≥n desde transacciones_clean (recovery desde eventos)

Rails **no** consume el t√≥pico `transacciones_clean` en tiempo normal (solo Telegraf lo lee para InfluxDB). Para recuperar la base de datos desde los eventos ya aprobados:

- **Cu√°ndo:** Tras p√©rdida de la tabla `transactions` o para repoblar desde la ‚Äúfuente de verdad‚Äù que son los eventos clean.
- **Comando:** `make recover-transactions-from-clean`
- **Qu√© hace:** Un consumidor one-off (rdkafka) lee desde el inicio del t√≥pico `transacciones_clean` y hace **upsert** por `event_id` en `transactions` (crea o actualiza, siempre con `aprobado: true`). Idempotente.
- **Limitaci√≥n:** Los mensajes clean no incluyen `numero_tarjeta`; esos campos quedar√°n vac√≠os tras la recuperaci√≥n. Opcionalmente se puede ejecutar despu√©s `make backfill-card-numbers` si los datos siguen en `transacciones_raw`.

Servicio: `RecoveryFromCleanService`. Rake: `rails data:recover_from_clean`. Tests: `bin/rails test test/services/recovery_from_clean_service_test.rb`.

### Regeneraci√≥n desde transacciones_raw (rewind del circuito normal)

Relee el t√≥pico `transacciones_raw` con el consumidor Karafka existente (`TransactionsConsumer`) para volver a crear las transacciones desde cero.

- **Cu√°ndo:** Para ‚Äúrebobinar‚Äù el flujo: borrar transacciones y repoblar desde raw (p. ej. tras cambiar reglas de categorizaci√≥n o corregir un bug en el consumer).
- **Comando:** `make regenerate-transactions-from-raw`
- **Qu√© hace:** 1) Borra solo la tabla `transactions` (`data:clean_transactions`). 2) Rebobina el consumer group `enrichment_manager_v3` al inicio del t√≥pico (y de `file_results`). 3) Reinicia el worker Karafka. El worker vuelve a consumir todos los mensajes de `transacciones_raw` y crea de nuevo los registros en `transactions` (pendientes de aprobaci√≥n).
- **Nota:** No hace falta modificar `TransactionsConsumer`; al borrar antes las transacciones, no hay registros aprobados que se salten.

Targets auxiliares:
- `make clean-transactions-only` ‚Äî Borra solo `transactions` (no `SourceFile`).
- `make rebind-karafka-consumer` ‚Äî Rebobina el consumer group al inicio.

### Backfill de numero_tarjeta

Las transacciones creadas antes de agregar el campo `numero_tarjeta` no tienen este dato. Los mensajes en Kafka `transacciones_raw` s√≠ lo incluyen. Tras una recuperaci√≥n desde `transacciones_clean` (que no incluye `numero_tarjeta`), o para completar registros antiguos:

**Opci√≥n recomendada (script directo):**

```bash
make backfill-card-numbers
```

El script (`DataBackfillService.backfill_numero_tarjeta`) lee desde el inicio del t√≥pico `transacciones_raw`, busca cada transacci√≥n por `event_id` y actualiza solo el campo `numero_tarjeta` si est√° vac√≠o. Idempotente. Presiona Ctrl+C para detener cuando quieras.

**Alternativa (rebind consumer):** Rebobinar el consumer group (`make rebind-karafka-consumer`) y reiniciar el worker. Requiere modificar temporalmente `TransactionsConsumer` para permitir actualizar aprobadas. Ver `make rebind-karafka-consumer` en el Makefile.

**Verificar resultados:**

```bash
docker compose exec web bin/rails runner "puts 'Con numero_tarjeta: ' + Transaction.where.not(numero_tarjeta: [nil, '']).count.to_s; puts 'Sin: ' + Transaction.where(numero_tarjeta: [nil, '']).count.to_s"
```

O usar `make check-card-numbers` para un resumen r√°pido.

**Notas:** Si Kafka ya purg√≥ los mensajes (retenci√≥n), no funcionar√°; habr√≠a que re-procesar los archivos originales desde MinIO. Si falla la conexi√≥n, verifica `docker compose ps redpanda` y `KAFKA_SERVERS` en `.env`.

---

## üìù Notas T√©cnicas y Mantenimiento

1. **Idempotencia:** El `event_id` (hash SHA-256) previene duplicados. Si un gasto ya fue aprobado, el pipeline de Rails lo ignorar√° si intentas re-ingestarlo.
2. **Karafka Boot:** Si el worker no arranca, verifica que `app/consumers/application_consumer.rb` exista y que `karafka.rb` use `"TransactionsConsumer"` como string.
3. **Persistencia:** Los datos residen en vol√∫menes nombrados de Docker (`postgres_data`, `influxdb_data`). No borrar a menos que se desee un hard-reset.
4. **Sincronizaci√≥n:** Recuerda: **Escribe c√≥digo en local, ejecuta en Docker.** Cualquier archivo generado con `rails generate` aparecer√° en tu carpeta local gracias a los vol√∫menes montados.

---
*Tip: Usa `Ctrl + Shift + V` en VS Code para previsualizar este documento.*
