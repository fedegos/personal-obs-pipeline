# 游 Runbook: Personal Observability Pipeline (Audit-X)
*Actualizado: 10 de enero, 2026*

## 游 1. Gesti칩n de Infraestructura (Docker)
El stack completo corre en contenedores. No es necesario instalar Ruby o Kafka localmente.

*   **Levantar el stack (Recomendado):**
    ```bash
    docker compose up -d
    ```
*   **Verificar salud de los servicios (Healthchecks):**
    ```bash
    docker compose ps
    ```
    *Nota: `redpanda` y `db` deben aparecer como `(healthy)` antes de que `web` inicie.*
*   **Logs espec칤ficos para depurar:**
    ```bash
    docker compose logs -f web            # Logs de la interfaz Rails
    docker compose logs -f karafka_worker # Logs del consumidor de Kafka
    ```
*   **Apagar y limpiar vol칰menes (Reset de DBs):**
    ```bash
    docker compose down -v
    ```

### 游깷 Dashboard de Control
- **Audit-X (Rails):** [http://localhost:3000](http://localhost:3000) (Gesti칩n y Aprobaci칩n)
- **Kafka UI:** [http://localhost:8080](http://localhost:8080) (Monitoreo de t칩picos)
- **Grafana:** [http://localhost:3001](http://localhost:3001) (Visualizaci칩n final)
- **InfluxDB:** [http://localhost:8086](http://localhost:8086) (M칠tricas Raw)

---

## 游눑 2. Configuraci칩n Inicial (Instalaci칩n)
Si agregaste gemas nuevas o est치s en una instalaci칩n limpia:

1. **Sincronizar Gemas:**
   ```bash
   docker compose run --rm web bundle install
   ```
2. **Preparar Base de Datos:**
   ```bash
   docker compose exec web rails db:prepare
   ```


---

## 游닌 3. Fase 1: Ingesta (Python)
Env칤a los datos de los extractores (Visa/Amex) hacia Kafka.

```bash
# Activar entorno virtual
source .venv/bin/activate
# Ejecutar ingesta
python main.py
```
*Los eventos quedar치n en el t칩pico `transacciones_raw` y entrar치n autom치ticamente a la web de Rails en estado "Pendiente".*

2. **Listar archivos en s3:**
```bash
docker exec -it minio_s3 mc alias set local http://localhost:9000 {user} {password}
```

```bash
docker exec -it minio_s3 mc du local/bank-ingestion
```
---

## 游댌 4. Fase 2: Curadur칤a y Enriquecimiento (Rails)
En esta fase, los datos est치n en PostgreSQL pero **no han llegado a InfluxDB**.

1. Entra a [http://localhost:3000/transactions](http://localhost:3000/transactions).
2. Revisa las categor칤as sugeridas por el `CategorizerService`.
3. Ajusta la categor칤a o el sentimiento si es necesario.
4. Presiona **"Aprobar"**. 
   *Esto publica el evento en `transacciones_clean`.*

---

## 游늵 5. Fase 3: Visualizaci칩n (Telegraf + Influx + Grafana)
El servicio **Telegraf** est치 configurado para mover autom치ticamente todo lo que aparece en el t칩pico `transacciones_clean` hacia InfluxDB.

1. Abre **Grafana** [http://localhost:3001](http://localhost:3001).
2. Usa el Data Source de InfluxDB (Bucket: `finanzas`).
3. Filtra por los tags: `categoria`, `sentimiento` o `red`.

---

## 游닇 Notas T칠cnicas y Mantenimiento

1. **Idempotencia:** El `event_id` (hash SHA-256) previene duplicados. Si un gasto ya fue aprobado, el pipeline de Rails lo ignorar치 si intentas re-ingestarlo.
2. **Karafka Boot:** Si el worker no arranca, verifica que `app/consumers/application_consumer.rb` exista y que `karafka.rb` use `"TransactionsConsumer"` como string.
3. **Persistencia:** Los datos residen en vol칰menes nombrados de Docker (`postgres_data`, `influxdb_data`). No borrar a menos que se desee un hard-reset.
4. **Sincronizaci칩n:** Recuerda: **Escribe c칩digo en local, ejecuta en Docker.** Cualquier archivo generado con `rails generate` aparecer치 en tu carpeta local gracias a los 

---
*Tip: Usa `Ctrl + Shift + V` en VS Code para previsualizar este documento.*
```` [1], [2], [3]
